=====================================================================================
% lrCostFunction.m

theta_X =  X*theta
h_theta_X = sigmoid(theta_X)
Original_J = -1/m*(y'*log(h_theta_X) + (ones(1,m) - y')*log(ones(m,1) - h_theta_X ))
Punishment_J = lambda/(2*m)* (theta'*theta - theta(1)*theta(1))
J = Original_J+Punishment_J

grad_original = (1/m.*((h_theta_X - y)'*X))'
grad_theta0 = grad_original(1)
grad = (1/m.*((h_theta_X - y)'*X))' + lambda/m*theta
grad(1) = grad_theta0

=====================================================================================
% oneVsAll.m

for i= 1:num_labels
    initial_theta = zeros(n + 1, 1);
    options = optimset('GradObj', 'on', 'MaxIter', 50);
    [theta] = ...
         fmincg (@(t)(lrCostFunction(t, X, (y == i), lambda)), ...
                 initial_theta, options);
    all_theta(i,:) = theta(:)
    
end

=====================================================================================
% predictOneVsAll.m

predict_prob = X* all_theta'
h_theta_X = sigmoid(predict_prob)
[i p] = max(h_theta_X,[],2)

=====================================================================================
% predict.m

a_1 = [ones(m, 1) X];
z_2 = a_1 * Theta1'
a_2 = sigmoid(z_2)
a_2 = [ones(m,1) a_2]
z_3 = a_2 * Theta2'
a_3 = sigmoid(z_3)
[i p] = max(a_3,[],2)

=====================================================================================
